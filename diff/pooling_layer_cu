diff --git a/src/caffe/layers/pooling_layer.cu b/src/caffe/layers/pooling_layer.cu
index d1d4850..556ecdc 100644
--- a/src/caffe/layers/pooling_layer.cu
+++ b/src/caffe/layers/pooling_layer.cu
@@ -7,6 +7,44 @@
 #include "caffe/vision_layers.hpp"
 
 namespace caffe {
+template <typename Dtype>
+__global__ void FCNMaxPoolForward(const int nthreads, const Dtype* bottom_data,
+    const int num, const int channels, const int height,
+    const int width, const int pooled_height, const int pooled_width,
+    const int kernel_h, const int kernel_w, const int ext_kernel_h, const int ext_kernel_w,
+    const int stride_h, const int stride_w, const int kstride_h, const int kstride_w, 
+    const int pad_h, const int pad_w, Dtype* top_data,
+    int* mask, Dtype* top_mask) {
+  CUDA_KERNEL_LOOP(index, nthreads) {
+    int pw = index % pooled_width;
+    int ph = (index / pooled_width) % pooled_height;
+    int c = (index / pooled_width / pooled_height) % channels;
+    int n = index / pooled_width / pooled_height / channels;
+    int hstart = ph * stride_h - pad_h;
+    int wstart = pw * stride_w - pad_w;
+    int hend = min(hstart + ext_kernel_h, height);
+    int wend = min(wstart + ext_kernel_w, width);
+    hstart = max(hstart, 0);
+    wstart = max(wstart, 0);
+    Dtype maxval = -FLT_MAX;
+    int maxidx = -1;
+    bottom_data += (n * channels + c) * height * width;
+    for (int h = hstart; h < hend; h += kstride_h) {
+      for (int w = wstart; w < wend; w += kstride_w) {
+        if (bottom_data[h * width + w] > maxval) {
+          maxidx = h * width + w;
+          maxval = bottom_data[maxidx];
+        }
+      }
+    }
+    top_data[index] = maxval;
+    if (mask) {
+      mask[index] = maxidx;
+    } else {
+      top_mask[index] = maxidx;
+    }
+  }
+}
 
 template <typename Dtype>
 __global__ void MaxPoolForward(const int nthreads, const Dtype* bottom_data,
@@ -160,50 +198,69 @@ void PoolingLayer<Dtype>::Forward_gpu(const vector<Blob<Dtype>*>& bottom,
   const bool use_top_mask = top.size() > 1;
   int* mask = NULL;
   Dtype* top_mask = NULL;
-  switch (this->layer_param_.pooling_param().pool()) {
-  case PoolingParameter_PoolMethod_MAX:
+
+  if ((kstride_h_ != 1) || (kstride_w_ != 1)) {
+    // we have validated the pooling type is MAX for FCN
     if (use_top_mask) {
       top_mask = top[1]->mutable_gpu_data();
     } else {
       mask = max_idx_.mutable_gpu_data();
     }
     // NOLINT_NEXT_LINE(whitespace/operators)
-    MaxPoolForward<Dtype><<<CAFFE_GET_BLOCKS(count), CAFFE_CUDA_NUM_THREADS>>>(
-        count, bottom_data, bottom[0]->num(), channels_,
-        height_, width_, pooled_height_, pooled_width_, kernel_h_,
-        kernel_w_, stride_h_, stride_w_, pad_h_, pad_w_, top_data,
-        mask, top_mask);
-    break;
-  case PoolingParameter_PoolMethod_AVE:
-    // NOLINT_NEXT_LINE(whitespace/operators)
-    AvePoolForward<Dtype><<<CAFFE_GET_BLOCKS(count), CAFFE_CUDA_NUM_THREADS>>>(
-        count, bottom_data, bottom[0]->num(), channels_,
-        height_, width_, pooled_height_, pooled_width_, kernel_h_,
-        kernel_w_, stride_h_, stride_w_, pad_h_, pad_w_, top_data);
-    break;
-  case PoolingParameter_PoolMethod_STOCHASTIC:
-    if (this->phase_ == TRAIN) {
-      // We need to create the random index as well.
-      caffe_gpu_rng_uniform(count, Dtype(0), Dtype(1),
-                            rand_idx_.mutable_gpu_data());
+    FCNMaxPoolForward<Dtype><<<CAFFE_GET_BLOCKS(count), CAFFE_CUDA_NUM_THREADS>>>(
+	count, bottom_data, bottom[0]->num(), channels_,
+	height_, width_, pooled_height_, pooled_width_, kernel_h_,
+	kernel_w_, ext_kernel_h_, ext_kernel_w_,
+	stride_h_, stride_w_, kstride_h_, kstride_w_,
+	pad_h_, pad_w_, top_data,
+	mask, top_mask);
+    return;
+  }
+
+  switch (this->layer_param_.pooling_param().pool()) {
+    case PoolingParameter_PoolMethod_MAX:
+      if (use_top_mask) {
+	top_mask = top[1]->mutable_gpu_data();
+      } else {
+	mask = max_idx_.mutable_gpu_data();
+      }
       // NOLINT_NEXT_LINE(whitespace/operators)
-      StoPoolForwardTrain<Dtype><<<CAFFE_GET_BLOCKS(count),
-                                   CAFFE_CUDA_NUM_THREADS>>>(
-          count, bottom_data, bottom[0]->num(), channels_,
-          height_, width_, pooled_height_, pooled_width_, kernel_h_,
-          kernel_w_, stride_h_, stride_w_,
-          rand_idx_.mutable_gpu_data(), top_data);
-    } else {
+      MaxPoolForward<Dtype><<<CAFFE_GET_BLOCKS(count), CAFFE_CUDA_NUM_THREADS>>>(
+	  count, bottom_data, bottom[0]->num(), channels_,
+	  height_, width_, pooled_height_, pooled_width_, kernel_h_,
+	  kernel_w_, stride_h_, stride_w_, pad_h_, pad_w_, top_data,
+	  mask, top_mask);
+      break;
+    case PoolingParameter_PoolMethod_AVE:
       // NOLINT_NEXT_LINE(whitespace/operators)
-      StoPoolForwardTest<Dtype><<<CAFFE_GET_BLOCKS(count),
-                                  CAFFE_CUDA_NUM_THREADS>>>(
-          count, bottom_data, bottom[0]->num(), channels_,
-          height_, width_, pooled_height_, pooled_width_, kernel_h_,
-          kernel_w_, stride_h_, stride_w_, top_data);
-    }
-    break;
-  default:
-    LOG(FATAL) << "Unknown pooling method.";
+      AvePoolForward<Dtype><<<CAFFE_GET_BLOCKS(count), CAFFE_CUDA_NUM_THREADS>>>(
+	  count, bottom_data, bottom[0]->num(), channels_,
+	  height_, width_, pooled_height_, pooled_width_, kernel_h_,
+	  kernel_w_, stride_h_, stride_w_, pad_h_, pad_w_, top_data);
+      break;
+    case PoolingParameter_PoolMethod_STOCHASTIC:
+      if (this->phase_ == TRAIN) {
+	// We need to create the random index as well.
+	caffe_gpu_rng_uniform(count, Dtype(0), Dtype(1),
+	    rand_idx_.mutable_gpu_data());
+	// NOLINT_NEXT_LINE(whitespace/operators)
+	StoPoolForwardTrain<Dtype><<<CAFFE_GET_BLOCKS(count),
+	  CAFFE_CUDA_NUM_THREADS>>>(
+	      count, bottom_data, bottom[0]->num(), channels_,
+	      height_, width_, pooled_height_, pooled_width_, kernel_h_,
+	      kernel_w_, stride_h_, stride_w_,
+	      rand_idx_.mutable_gpu_data(), top_data);
+      } else {
+	// NOLINT_NEXT_LINE(whitespace/operators)
+	StoPoolForwardTest<Dtype><<<CAFFE_GET_BLOCKS(count),
+	  CAFFE_CUDA_NUM_THREADS>>>(
+	      count, bottom_data, bottom[0]->num(), channels_,
+	      height_, width_, pooled_height_, pooled_width_, kernel_h_,
+	      kernel_w_, stride_h_, stride_w_, top_data);
+      }
+      break;
+    default:
+      LOG(FATAL) << "Unknown pooling method.";
   }
   CUDA_POST_KERNEL_CHECK;
 }
@@ -224,10 +281,10 @@ __global__ void MaxPoolBackward(const int nthreads, const Dtype* top_diff,
     int c = (index / width / height) % channels;
     int n = index / width / height / channels;
     int phstart =
-        (h + pad_h < kernel_h) ? 0 : (h + pad_h - kernel_h) / stride_h + 1;
+      (h + pad_h < kernel_h) ? 0 : (h + pad_h - kernel_h) / stride_h + 1;
     int phend = min((h + pad_h) / stride_h + 1, pooled_height);
     int pwstart =
-        (w + pad_w < kernel_w) ? 0 : (w + pad_w - kernel_w) / stride_w + 1;
+      (w + pad_w < kernel_w) ? 0 : (w + pad_w - kernel_w) / stride_w + 1;
     int pwend = min((w + pad_w) / stride_w + 1, pooled_width);
     Dtype gradient = 0;
     int offset = (n * channels + c) * pooled_height * pooled_width;
@@ -235,20 +292,20 @@ __global__ void MaxPoolBackward(const int nthreads, const Dtype* top_diff,
     if (mask) {
       mask += offset;
       for (int ph = phstart; ph < phend; ++ph) {
-        for (int pw = pwstart; pw < pwend; ++pw) {
-          if (mask[ph * pooled_width + pw] == h * width + w) {
-            gradient += top_diff[ph * pooled_width + pw];
-          }
-        }
+	for (int pw = pwstart; pw < pwend; ++pw) {
+	  if (mask[ph * pooled_width + pw] == h * width + w) {
+	    gradient += top_diff[ph * pooled_width + pw];
+	  }
+	}
       }
     } else {
       top_mask += offset;
       for (int ph = phstart; ph < phend; ++ph) {
-        for (int pw = pwstart; pw < pwend; ++pw) {
-          if (top_mask[ph * pooled_width + pw] == h * width + w) {
-            gradient += top_diff[ph * pooled_width + pw];
-          }
-        }
+	for (int pw = pwstart; pw < pwend; ++pw) {
+	  if (top_mask[ph * pooled_width + pw] == h * width + w) {
+	    gradient += top_diff[ph * pooled_width + pw];
+	  }
+	}
       }
     }
     bottom_diff[index] = gradient;
@@ -277,13 +334,13 @@ __global__ void AvePoolBackward(const int nthreads, const Dtype* top_diff,
     top_diff += (n * channels + c) * pooled_height * pooled_width;
     for (int ph = phstart; ph < phend; ++ph) {
       for (int pw = pwstart; pw < pwend; ++pw) {
-        // figure out the pooling size
-        int hstart = ph * stride_h - pad_h;
-        int wstart = pw * stride_w - pad_w;
-        int hend = min(hstart + kernel_h, height + pad_h);
-        int wend = min(wstart + kernel_w, width + pad_w);
-        int pool_size = (hend - hstart) * (wend - wstart);
-        gradient += top_diff[ph * pooled_width + pw] / pool_size;
+	// figure out the pooling size
+	int hstart = ph * stride_h - pad_h;
+	int wstart = pw * stride_w - pad_w;
+	int hend = min(hstart + kernel_h, height + pad_h);
+	int wend = min(wstart + kernel_w, width + pad_w);
+	int pool_size = (hend - hstart) * (wend - wstart);
+	gradient += top_diff[ph * pooled_width + pw] / pool_size;
       }
     }
     bottom_diff[index] = gradient;
@@ -314,8 +371,8 @@ __global__ void StoPoolBackward(const int nthreads,
     top_diff += (n * channels + c) * pooled_height * pooled_width;
     for (int ph = phstart; ph < phend; ++ph) {
       for (int pw = pwstart; pw < pwend; ++pw) {
-        gradient += top_diff[ph * pooled_width + pw] *
-            (index == static_cast<int>(rand_idx[ph * pooled_width + pw]));
+	gradient += top_diff[ph * pooled_width + pw] *
+	  (index == static_cast<int>(rand_idx[ph * pooled_width + pw]));
       }
     }
     bottom_diff[index] = gradient;
@@ -325,7 +382,8 @@ __global__ void StoPoolBackward(const int nthreads,
 
 template <typename Dtype>
 void PoolingLayer<Dtype>::Backward_gpu(const vector<Blob<Dtype>*>& top,
-      const vector<bool>& propagate_down, const vector<Blob<Dtype>*>& bottom) {
+    const vector<bool>& propagate_down, const vector<Blob<Dtype>*>& bottom) {
+  CHECK((kstride_h_ == 1) && (kstride_w_ == 1)) << "Backward_gpu is not implemented for FCN pooling";
   if (!propagate_down[0]) {
     return;
   }
@@ -338,36 +396,36 @@ void PoolingLayer<Dtype>::Backward_gpu(const vector<Blob<Dtype>*>& top,
   const int* mask = NULL;
   const Dtype* top_mask = NULL;
   switch (this->layer_param_.pooling_param().pool()) {
-  case PoolingParameter_PoolMethod_MAX:
-    if (use_top_mask) {
-      top_mask = top[1]->gpu_data();
-    } else {
-      mask = max_idx_.gpu_data();
-    }
-    // NOLINT_NEXT_LINE(whitespace/operators)
-    MaxPoolBackward<Dtype><<<CAFFE_GET_BLOCKS(count), CAFFE_CUDA_NUM_THREADS>>>(
-        count, top_diff, mask, top_mask, top[0]->num(), channels_,
-        height_, width_, pooled_height_, pooled_width_,
-        kernel_h_, kernel_w_, stride_h_, stride_w_, pad_h_, pad_w_,
-        bottom_diff);
-    break;
-  case PoolingParameter_PoolMethod_AVE:
-    // NOLINT_NEXT_LINE(whitespace/operators)
-    AvePoolBackward<Dtype><<<CAFFE_GET_BLOCKS(count), CAFFE_CUDA_NUM_THREADS>>>(
-        count, top_diff, top[0]->num(), channels_,
-        height_, width_, pooled_height_, pooled_width_, kernel_h_,
-        kernel_w_, stride_h_, stride_w_, pad_h_, pad_w_, bottom_diff);
-    break;
-  case PoolingParameter_PoolMethod_STOCHASTIC:
-    // NOLINT_NEXT_LINE(whitespace/operators)
-    StoPoolBackward<Dtype><<<CAFFE_GET_BLOCKS(count), CAFFE_CUDA_NUM_THREADS>>>(
-        count, rand_idx_.gpu_data(), top_diff,
-        top[0]->num(), channels_, height_, width_, pooled_height_,
-        pooled_width_, kernel_h_, kernel_w_, stride_h_, stride_w_,
-        bottom_diff);
-    break;
-  default:
-    LOG(FATAL) << "Unknown pooling method.";
+    case PoolingParameter_PoolMethod_MAX:
+      if (use_top_mask) {
+	top_mask = top[1]->gpu_data();
+      } else {
+	mask = max_idx_.gpu_data();
+      }
+      // NOLINT_NEXT_LINE(whitespace/operators)
+      MaxPoolBackward<Dtype><<<CAFFE_GET_BLOCKS(count), CAFFE_CUDA_NUM_THREADS>>>(
+	  count, top_diff, mask, top_mask, top[0]->num(), channels_,
+	  height_, width_, pooled_height_, pooled_width_,
+	  kernel_h_, kernel_w_, stride_h_, stride_w_, pad_h_, pad_w_,
+	  bottom_diff);
+      break;
+    case PoolingParameter_PoolMethod_AVE:
+      // NOLINT_NEXT_LINE(whitespace/operators)
+      AvePoolBackward<Dtype><<<CAFFE_GET_BLOCKS(count), CAFFE_CUDA_NUM_THREADS>>>(
+	  count, top_diff, top[0]->num(), channels_,
+	  height_, width_, pooled_height_, pooled_width_, kernel_h_,
+	  kernel_w_, stride_h_, stride_w_, pad_h_, pad_w_, bottom_diff);
+      break;
+    case PoolingParameter_PoolMethod_STOCHASTIC:
+      // NOLINT_NEXT_LINE(whitespace/operators)
+      StoPoolBackward<Dtype><<<CAFFE_GET_BLOCKS(count), CAFFE_CUDA_NUM_THREADS>>>(
+	  count, rand_idx_.gpu_data(), top_diff,
+	  top[0]->num(), channels_, height_, width_, pooled_height_,
+	  pooled_width_, kernel_h_, kernel_w_, stride_h_, stride_w_,
+	  bottom_diff);
+      break;
+    default:
+      LOG(FATAL) << "Unknown pooling method.";
   }
   CUDA_POST_KERNEL_CHECK;
 }
